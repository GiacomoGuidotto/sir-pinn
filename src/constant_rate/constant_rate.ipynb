{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "65fffccded80afc6",
            "metadata": {},
            "source": [
                "# SIR model: inverse problem\n",
                "## A PINN approach\n",
                "\n",
                "In this notebook, we will solve the inverse problem of the SIR model using a Physics-Informed Neural Network (PINN). The goal is to estimate the infection rate $\\beta$ from the observed data of the infected population. To do this, we will train a PINN model, where we compute the residuals of the differential equation system with initial conditions and the data loss simultaneously.\n",
                "\n",
                "The SIR model is governed by the following set of ordinary differential equations (ODEs):\n",
                "\n",
                "$$\n",
                "\\begin{cases}\n",
                "\\frac{dS}{dt} &= -\\frac{\\beta}{N} I S, \\\\\n",
                "\\frac{dI}{dt} &= \\frac{\\beta}{N} I S - \\delta I, \\\\\n",
                "\\frac{dR}{dt} &= \\delta I,\n",
                "\\end{cases}\n",
                "$$\n",
                "\n",
                "where $t \\in [0, 90]$ and with the initial conditions $S(0) = N - 1$, $I(0) = 1$, and $R(0) = 0$."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e2b13f713fe59120",
            "metadata": {},
            "source": [
                "## Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4e31b153caf564bf",
            "metadata": {},
            "outputs": [],
            "source": [
                "from dataclasses import dataclass, field\n",
                "from IPython.display import display, HTML\n",
                "from lightning import Callback\n",
                "from lightning.pytorch import Trainer, LightningModule\n",
                "from lightning.pytorch.callbacks import LearningRateMonitor, EarlyStopping\n",
                "from lightning.pytorch.loggers import TensorBoardLogger, CSVLogger\n",
                "import matplotlib.pyplot as plt\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "from scipy.integrate import odeint\n",
                "from sklearn.metrics import mean_absolute_percentage_error\n",
                "import seaborn as sns\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "from typing import List, Tuple\n",
                "\n",
                "sns.set_theme(style=\"darkgrid\")\n",
                "\n",
                "%reload_ext tensorboard\n",
                "%tensorboard --logdir=logs/tensorboard"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "638b5816",
            "metadata": {},
            "source": [
                "## Module's components"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 75,
            "id": "4a5013ab",
            "metadata": {},
            "outputs": [],
            "source": [
                "class Square(nn.Module):\n",
                "    \"\"\"A module that squares its input element-wise.\"\"\"\n",
                "    @staticmethod\n",
                "    def forward(x):\n",
                "        return torch.square(x)\n",
                "\n",
                "\n",
                "def create_mlp(layers_dims, activation, output_activation):\n",
                "    \"\"\"Create a multi-layer perceptron with specified architecture.\"\"\"\n",
                "    layers = []\n",
                "    for i in range(len(layers_dims) - 1):\n",
                "        layers.append(nn.Linear(layers_dims[i], layers_dims[i + 1]))\n",
                "        if i < len(layers_dims) - 2:\n",
                "            layers.append(activation)\n",
                "    layers.append(output_activation)\n",
                "\n",
                "    net = nn.Sequential(*layers)\n",
                "\n",
                "    for layer in net:\n",
                "        if isinstance(layer, nn.Linear):\n",
                "            nn.init.xavier_normal_(layer.weight)\n",
                "            nn.init.zeros_(layer.bias)\n",
                "\n",
                "    return net\n",
                "\n",
                "\n",
                "activation_map = {\n",
                "    'tanh': nn.Tanh(),\n",
                "    'relu': nn.ReLU(),\n",
                "    'leaky_relu': nn.LeakyReLU(),\n",
                "    'sigmoid': nn.Sigmoid(),\n",
                "    'selu': nn.SELU(),\n",
                "    'square': Square(),\n",
                "    'softplus': nn.Softplus(),\n",
                "    'identity': nn.Identity()\n",
                "}"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2ffcfb17",
            "metadata": {},
            "source": [
                "## Module's configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 76,
            "id": "33bd675d",
            "metadata": {},
            "outputs": [],
            "source": [
                "@dataclass\n",
                "class SIRConfig:\n",
                "    \"\"\"Configuration for SIR PINN model and training.\"\"\"\n",
                "    # Model parameters\n",
                "    N: float = 56e6\n",
                "    delta: float = 1 / 5\n",
                "    r0: float = 3.0\n",
                "    beta_true: float = delta * r0\n",
                "    initial_beta: float = 0.5\n",
                "    \n",
                "    # Neural network architecture\n",
                "    hidden_layers: List[int] = field(default_factory=lambda: 4 * [50])\n",
                "    activation: str = 'tanh'\n",
                "    output_activation: str = 'softplus'\n",
                "    \n",
                "    # Initial conditions (I0, R0)\n",
                "    initial_conditions: List[float] = field(default_factory=lambda: [1., 0.])\n",
                "    \n",
                "    # Training parameters\n",
                "    learning_rate: float = 1e-3\n",
                "    batch_size: int = 100\n",
                "    max_epochs: int = 1000\n",
                "    \n",
                "    # Scheduler parameters\n",
                "    scheduler_factor: float = 0.5\n",
                "    scheduler_patience: int = 100\n",
                "    scheduler_threshold: float = 0.01\n",
                "    scheduler_min_lr: float = 1e-6\n",
                "    \n",
                "    # Early stopping\n",
                "    early_stopping_patience: int = 500\n",
                "    \n",
                "    # Loss weights\n",
                "    pde_weight: float = 1.\n",
                "    ic_weight: float = 1.\n",
                "    data_weight: float = 10.\n",
                "    \n",
                "    # Dataset parameters\n",
                "    time_domain: Tuple[int, int] = (0, 90)\n",
                "    collocation_points: int = 6000\n",
                "    \n",
                "    # Logging\n",
                "    log_every_n_steps: int = 61"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "7120ac1ce626e51c",
            "metadata": {},
            "source": [
                "## Dataset creation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 77,
            "id": "7602c2b769e44162",
            "metadata": {},
            "outputs": [],
            "source": [
                "class SIRDataset(Dataset):\n",
                "    \"\"\"Dataset for SIR PINN training.\"\"\"\n",
                "    def __init__(\n",
                "        self, \n",
                "        t_obs: np.ndarray, \n",
                "        i_obs: np.ndarray, \n",
                "        time_domain: Tuple[float, float], \n",
                "        n_collocation: int,\n",
                "        N: float\n",
                "    ):\n",
                "        \"\"\"\n",
                "        Initialize dataset with observation points and random collocation points.\n",
                "        The infected population is normalized to be in the range [0, 1].\n",
                "        \n",
                "        Args:\n",
                "            t_obs: Observation time points\n",
                "            i_obs: Observed infected population at each time point\n",
                "            time_domain: (t_min, t_max) time range\n",
                "            n_collocation: Number of random collocation points to generate\n",
                "        \"\"\"\n",
                "        t_min, t_max = time_domain\n",
                "        self.t_obs = torch.tensor(t_obs, dtype=torch.float32).reshape(-1, 1)\n",
                "\n",
                "        i_norm = i_obs / N\n",
                "        self.i_obs = torch.tensor(i_norm, dtype=torch.float32).reshape(-1, 1)\n",
                "\n",
                "        t_rand = np.expm1(np.random.uniform(np.log1p(t_min), np.log1p(t_max), n_collocation))\n",
                "        self.t_collocation = torch.tensor(t_rand, dtype=torch.float32).reshape(-1, 1)\n",
                "        \n",
                "        self.t_combined = torch.cat([self.t_obs, self.t_collocation], dim=0)\n",
                "        \n",
                "        self.is_obs = torch.zeros(len(self.t_combined), dtype=torch.bool)\n",
                "        self.is_obs[:len(self.t_obs)] = True\n",
                "        \n",
                "        self.i_targets = torch.zeros(len(self.t_combined), 1, dtype=torch.float32)\n",
                "        self.i_targets[:len(self.t_obs)] = self.i_obs\n",
                "        \n",
                "    def __len__(self):\n",
                "        return len(self.t_combined)\n",
                "    \n",
                "    def __getitem__(self, idx):\n",
                "        return {\n",
                "            't': self.t_combined[idx],\n",
                "            'is_obs': self.is_obs[idx],\n",
                "            'i_target': self.i_targets[idx]\n",
                "        }"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cb36a9738f8dd15c",
            "metadata": {},
            "source": [
                "## Module definition"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 78,
            "id": "998d6e196fb0334a",
            "metadata": {},
            "outputs": [],
            "source": [
                "class SIRPINN(LightningModule):\n",
                "    \"\"\"Physics-Informed Neural Network for SIR model parameter identification.\"\"\"\n",
                "    \n",
                "    def __init__(self, config: SIRConfig):\n",
                "        super().__init__()\n",
                "        self.save_hyperparameters()\n",
                "        self.config = config\n",
                "        \n",
                "        layers_dims = [1] + config.hidden_layers + [1]\n",
                "        activation = activation_map.get(config.activation)\n",
                "        output_activation = activation_map.get(config.output_activation)\n",
                "        \n",
                "        self.net_S = create_mlp(layers_dims, activation, output_activation)\n",
                "        self.net_I = create_mlp(layers_dims, activation, output_activation)\n",
                "        \n",
                "        self.beta = nn.Parameter(torch.tensor(config.initial_beta, dtype=torch.float32))\n",
                "        \n",
                "        self.N = 1.\n",
                "        self.delta = config.delta\n",
                "        \n",
                "        self.loss_fn = nn.MSELoss()\n",
                "\n",
                "        self.t0_tensor = torch.zeros(1, 1, device=self.device, dtype=torch.float32)\n",
                "        i0, r0 = map(lambda x: x / self.config.N, self.config.initial_conditions)\n",
                "        ic = [self.N - i0 - r0, i0, r0]\n",
                "        self.ic_true = torch.tensor(ic, dtype=torch.float32).reshape(1, 3)\n",
                "\n",
                "    def forward(self, t: torch.Tensor) -> torch.Tensor:\n",
                "        \"\"\"\n",
                "        Forward pass to compute S, I, R values at time t.\n",
                "        \n",
                "        Args:\n",
                "            t: Time points tensor of shape [batch_size, 1]\n",
                "            \n",
                "        Returns:\n",
                "            Tensor of shape [batch_size, 3] with [S, I, R] values\n",
                "        \"\"\"\n",
                "        S = self.net_S(t)\n",
                "        I = self.net_I(t)\n",
                "        R = self.N - S - I\n",
                "        \n",
                "        return torch.cat([S, I, R], dim=1)\n",
                "        \n",
                "    @torch.inference_mode(False)\n",
                "    def compute_ode_residuals(self, t_tensor: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
                "        \"\"\"\n",
                "        Compute residuals of the SIR ODEs using automatic differentiation.\n",
                "        \n",
                "        Args:\n",
                "            t: Time points tensor of shape [batch_size, 1]\n",
                "            \n",
                "        Returns:\n",
                "            Tuple of residual tensors (res_S, res_I)\n",
                "        \"\"\"\n",
                "        t_tensor.requires_grad_(True)\n",
                "        S = self.net_S(t_tensor)\n",
                "        I = self.net_I(t_tensor)\n",
                "        \n",
                "        dS_dt = torch.autograd.grad(\n",
                "            S, t_tensor, grad_outputs=torch.ones_like(S), create_graph=True\n",
                "        )[0]\n",
                "        dI_dt = torch.autograd.grad(\n",
                "            I, t_tensor, grad_outputs=torch.ones_like(I), create_graph=True\n",
                "        )[0]\n",
                "\n",
                "        res_S = dS_dt + self.beta * S * I\n",
                "        res_I = dI_dt - self.beta * S * I + self.delta * I\n",
                "\n",
                "        return res_S, res_I\n",
                "    \n",
                "    def pde_loss(self, t: torch.Tensor) -> torch.Tensor:\n",
                "        \"\"\"Compute PDE residual loss.\"\"\"\n",
                "        res_S, res_I = self.compute_ode_residuals(t)\n",
                "        loss_S = self.loss_fn(res_S, torch.zeros_like(res_S))\n",
                "        loss_I = self.loss_fn(res_I, torch.zeros_like(res_I))\n",
                "\n",
                "        return loss_S + loss_I\n",
                "    \n",
                "    def ic_loss(self) -> torch.Tensor:\n",
                "        \"\"\"Compute initial condition loss.\"\"\"\n",
                "        t0_tensor = self.t0_tensor.to(self.device)\n",
                "        ic_true = self.ic_true.to(self.device)\n",
                "        ic_pred = self(t0_tensor)\n",
                "\n",
                "        return self.loss_fn(ic_pred, ic_true)\n",
                "    \n",
                "    def data_loss(self, t_obs: torch.Tensor, i_obs: torch.Tensor) -> torch.Tensor:\n",
                "        \"\"\"Compute data fitting loss.\"\"\"\n",
                "        if t_obs.shape[0] == 0:  # No observations in batch\n",
                "            return torch.tensor(0.0, device=self.device)     \n",
                "           \n",
                "        i_pred = self(t_obs)[:, 1].reshape(-1, 1)\n",
                "        return self.loss_fn(i_pred, i_obs)\n",
                "    \n",
                "    def training_step(self, batch):\n",
                "        t = batch['t']\n",
                "        is_obs = batch['is_obs']\n",
                "        i_target = batch['i_target']\n",
                "        \n",
                "        t_obs = t[is_obs] if is_obs.any() else torch.zeros((0, 1), device=self.device)\n",
                "        i_obs = i_target[is_obs] if is_obs.any() else torch.zeros((0, 1), device=self.device)\n",
                "        \n",
                "        pde_loss_val = self.pde_loss(t)\n",
                "        ic_loss_val = self.ic_loss()\n",
                "        data_loss_val = self.data_loss(t_obs, i_obs)\n",
                "        \n",
                "        total_loss = (\n",
                "            self.config.pde_weight * pde_loss_val +\n",
                "            self.config.ic_weight * ic_loss_val +\n",
                "            self.config.data_weight * data_loss_val\n",
                "        )\n",
                "        \n",
                "        self.log('train/pde_loss', pde_loss_val)\n",
                "        self.log('train/ic_loss', ic_loss_val)\n",
                "        self.log('train/data_loss', data_loss_val)\n",
                "        self.log('train/total_loss', total_loss, prog_bar=True)\n",
                "        self.log('train/beta', self.beta.item(), prog_bar=True)\n",
                "        \n",
                "        return total_loss\n",
                "    \n",
                "    @torch.no_grad()\n",
                "    def predict_sir(self, t):\n",
                "        \"\"\"Predict SIR values at specified time points.\"\"\"\n",
                "        t_tensor = torch.tensor(t, dtype=torch.float32).reshape(-1, 1).to(self.device)\n",
                "        return self(t_tensor).cpu().numpy() * self.config.N\n",
                "    \n",
                "    def configure_optimizers(self):\n",
                "        optimizer = torch.optim.Adam(\n",
                "            self.parameters(), \n",
                "            lr=self.config.learning_rate\n",
                "        )\n",
                "        \n",
                "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
                "            optimizer,\n",
                "            mode='min',\n",
                "            factor=self.config.scheduler_factor,\n",
                "            patience=self.config.scheduler_patience,\n",
                "            threshold=self.config.scheduler_threshold,\n",
                "            min_lr=self.config.scheduler_min_lr\n",
                "        )\n",
                "        \n",
                "        return {\n",
                "            'optimizer': optimizer,\n",
                "            'lr_scheduler': {\n",
                "                'scheduler': scheduler,\n",
                "                'monitor': 'train/total_loss',\n",
                "                'interval': 'epoch',\n",
                "                'frequency': 1\n",
                "            }\n",
                "        }"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "1e0b9eaa",
            "metadata": {},
            "source": [
                "## Training definition"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 79,
            "id": "45bc6a5a",
            "metadata": {},
            "outputs": [],
            "source": [
                "def train_sir_pinn(t_obs: np.ndarray, i_obs: np.ndarray, config: SIRConfig) -> SIRPINN:\n",
                "    \"\"\"\n",
                "    Train a SIR PINN model using the provided observations.\n",
                "    \n",
                "    Args:\n",
                "        t_obs: Observation time points\n",
                "        i_obs: Observed infected proportions\n",
                "        override_config: Configuration object (optional)\n",
                "        \n",
                "    Returns:\n",
                "        Trained PINN model\n",
                "    \"\"\"\n",
                "    \n",
                "    dataset = SIRDataset(\n",
                "        t_obs=t_obs,\n",
                "        i_obs=i_obs,\n",
                "        time_domain=config.time_domain,\n",
                "        n_collocation=config.collocation_points,\n",
                "        N=config.N\n",
                "    )\n",
                "\n",
                "    data_loader = DataLoader(\n",
                "        dataset,\n",
                "        batch_size=config.batch_size,\n",
                "        shuffle=True,\n",
                "        # num_workers=7, # unavailable on Jupyter Notebooks\n",
                "        # persistent_workers=True\n",
                "    )\n",
                "    \n",
                "    model = SIRPINN(config)\n",
                "\n",
                "    callbacks: list[Callback] = [\n",
                "        EarlyStopping(\n",
                "            monitor='train/total_loss',\n",
                "            patience=config.early_stopping_patience,\n",
                "            mode='min'\n",
                "        ),\n",
                "        LearningRateMonitor(\n",
                "            logging_interval='epoch',\n",
                "        )\n",
                "    ]\n",
                "\n",
                "    loggers = [\n",
                "        TensorBoardLogger(save_dir=\"logs/tensorboard\", name=\"\"),\n",
                "        CSVLogger(save_dir=\"logs/csv\", name=\"\")\n",
                "    ]\n",
                "\n",
                "    trainer = Trainer(\n",
                "        max_epochs=config.max_epochs,\n",
                "        callbacks=callbacks,\n",
                "        log_every_n_steps=config.log_every_n_steps,\n",
                "        logger=loggers,\n",
                "    )\n",
                "    \n",
                "    trainer.fit(model, data_loader)\n",
                "    \n",
                "    return model"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "fe623e70",
            "metadata": {},
            "source": [
                "## Execution \n",
                "\n",
                "Generate syntethic data:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 80,
            "id": "58d0265a",
            "metadata": {},
            "outputs": [],
            "source": [
                "config = SIRConfig(\n",
                "  learning_rate=1e-4,\n",
                "  scheduler_patience=80\n",
                ")\n",
                "\n",
                "def sir(x, _, d, b):\n",
                "  s, i, _ = x\n",
                "  l = b * i / config.N\n",
                "  ds_dt = -l * s\n",
                "  di_dt = l * s - d * i\n",
                "  dr_dt = d * i\n",
                "  return np.array([ds_dt, di_dt, dr_dt])\n",
                "\n",
                "i0, r0 = config.initial_conditions\n",
                "t_start, t_end = config.time_domain\n",
                "\n",
                "t = np.linspace(t_start, t_end, t_end - t_start + 1)\n",
                "\n",
                "solution = odeint(sir, [config.N - i0 - r0, i0, r0], t, args=(config.delta, config.beta_true))\n",
                "s_true = solution[:, 0]\n",
                "i_true = solution[:, 1]\n",
                "r_true = solution[:, 2]\n",
                "\n",
                "i_obs = np.random.poisson(i_true)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "11d91587",
            "metadata": {},
            "outputs": [],
            "source": [
                "model = train_sir_pinn(t, i_obs, config)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "f2d0a782",
            "metadata": {},
            "source": [
                "## Evaluation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e1af5d8b",
            "metadata": {},
            "outputs": [],
            "source": [
                "s_pred, i_pred, r_pred = model.predict_sir(t).T\n",
                "beta_pred = model.beta.item()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d5fde243",
            "metadata": {},
            "source": [
                "Model predition"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a2e75ea2",
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(12, 6))\n",
                "\n",
                "sns.lineplot(x=t, y=s_true, label=\"$S_{\\\\mathrm{true}}$\")\n",
                "sns.lineplot(x=t, y=s_pred, label=\"$S_{\\\\mathrm{pred}}$\", linestyle=\"--\")\n",
                "sns.lineplot(x=t, y=i_true, label=\"$I_{\\\\mathrm{true}}$\")\n",
                "sns.lineplot(x=t, y=i_pred, label=\"$I_{\\\\mathrm{pred}}$\", linestyle=\"--\")\n",
                "sns.lineplot(x=t, y=r_true, label=\"$R_{\\\\mathrm{true}}$\")\n",
                "sns.lineplot(x=t, y=r_pred, label=\"$R_{\\\\mathrm{pred}}$\", linestyle=\"--\")\n",
                "\n",
                "plt.title('True vs Predicted SIR Dynamics (predicted $\\\\beta$ = {pred_beta:.4f})', fontsize=14)\n",
                "plt.xlabel('Time (days)', fontsize=12)\n",
                "plt.ylabel('Fraction of Population', fontsize=12)\n",
                "plt.legend()\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5f4ea337",
            "metadata": {},
            "source": [
                "Preditions accuracy"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d0af0c9e",
            "metadata": {},
            "outputs": [],
            "source": [
                "def mse(pred, true):\n",
                "  \"\"\"Calculate Mean Squared Error between predicted and true values.\"\"\"\n",
                "  return np.mean((pred - true) ** 2)\n",
                "\n",
                "\n",
                "def re(pred, true):\n",
                "  \"\"\"Calculate Relative Error between predicted and true values.\"\"\"\n",
                "  return np.linalg.norm(true - pred, 2) / np.linalg.norm(true, 2)\n",
                "\n",
                "\n",
                "def mape(pred, true):\n",
                "  \"\"\"Calculate Mean Absolute Percentage Error between predicted and true values.\"\"\"\n",
                "  return mean_absolute_percentage_error(true, pred)\n",
                "\n",
                "\n",
                "compartments = [\"S\", \"I\", \"R\"]\n",
                "pred_arrays = [s_pred, i_pred, r_pred]\n",
                "true_arrays = [s_true, i_true, r_true]\n",
                "\n",
                "mse_values = [\n",
                "  f\"{mse(pred, true):.2e}\" for pred, true in zip(pred_arrays, true_arrays)\n",
                "]\n",
                "re_values = [\n",
                "  f\"{re(pred, true):.2e}\" for pred, true in zip(pred_arrays, true_arrays)\n",
                "]\n",
                "mape_values = [\n",
                "  f\"{mape(pred, true):.2e}\" for pred, true in zip(pred_arrays, true_arrays)\n",
                "]\n",
                "\n",
                "errors = pd.DataFrame(\n",
                "  {\n",
                "    \"Compartment\": compartments,\n",
                "    \"MSE\":         mse_values,\n",
                "    \"MAPE (%)\":    mape_values,\n",
                "    \"RE\":          re_values,\n",
                "  }\n",
                ")\n",
                "\n",
                "display(HTML(errors.to_html(index=False)))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c86ad352",
            "metadata": {},
            "outputs": [],
            "source": [
                "beta_error = abs(beta_pred - config.beta_true)\n",
                "beta_error_percent = beta_error / config.beta_true * 100\n",
                "\n",
                "beta_errors = pd.DataFrame(\n",
                "  {\n",
                "    \"Parameter\":          [\"β\"],\n",
                "    \"Predicted Value\":    [f\"{beta_pred:.4f}\"],\n",
                "    \"True Value\":         [f\"{config.beta_true:.4f}\"],\n",
                "    \"Absolute Error\":     [f\"{beta_error:.2e}\"],\n",
                "    \"Relative Error (%)\": [f\"{beta_error_percent:.2f}%\"],\n",
                "  }\n",
                ")\n",
                "\n",
                "display(HTML(beta_errors.to_html(index=False)))"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "pinn",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.21"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
