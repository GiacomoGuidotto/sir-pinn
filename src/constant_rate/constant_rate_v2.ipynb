{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "65fffccded80afc6",
            "metadata": {},
            "source": [
                "# SIR model: inverse problem\n",
                "## A PINN approach\n",
                "\n",
                "In this notebook, we will solve the inverse problem of the SIR model using a Physics-Informed Neural Network (PINN). The goal is to estimate the infection rate $\\beta$ from the observed data of the infected population. To do this, we will train a PINN model, where we compute the residuals of the differential equation system with initial conditions and the data loss simultaneously.\n",
                "\n",
                "The SIR model is governed by the following set of ordinary differential equations (ODEs):\n",
                "\n",
                "$$\n",
                "\\begin{cases}\n",
                "\\frac{dS}{dt} &= -\\frac{\\beta}{N} I S, \\\\\n",
                "\\frac{dI}{dt} &= \\frac{\\beta}{N} I S - \\delta I, \\\\\n",
                "\\frac{dR}{dt} &= \\delta I,\n",
                "\\end{cases}\n",
                "$$\n",
                "\n",
                "where $t \\in [0, 90]$ and with the initial conditions $S(0) = N - 1$, $I(0) = 1$, and $R(0) = 0$."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e2b13f713fe59120",
            "metadata": {},
            "source": [
                "## Configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 28,
            "id": "4e31b153caf564bf",
            "metadata": {},
            "outputs": [],
            "source": [
                "import torch\n",
                "import torch.nn as nn\n",
                "import numpy as np\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "from dataclasses import dataclass\n",
                "from typing import List, Tuple\n",
                "from scipy.integrate import odeint\n",
                "import seaborn as sns\n",
                "import matplotlib.pyplot as plt\n",
                "from dataclasses import dataclass, field\n",
                "from lightning.pytorch import Trainer, LightningModule\n",
                "from lightning.pytorch.loggers import TensorBoardLogger\n",
                "from lightning.pytorch.callbacks import LearningRateMonitor\n",
                "\n",
                "\n",
                "sns.set_theme(style=\"darkgrid\")\n",
                "\n",
                "figures_dir = \"figures\""
            ]
        },
        {
            "cell_type": "markdown",
            "id": "638b5816",
            "metadata": {},
            "source": [
                "## Module's components"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 29,
            "id": "4a5013ab",
            "metadata": {},
            "outputs": [],
            "source": [
                "class Square(nn.Module):\n",
                "    \"\"\"A module that squares its input element-wise.\"\"\"\n",
                "    @staticmethod\n",
                "    def forward(x):\n",
                "        return torch.square(x)\n",
                "\n",
                "\n",
                "def create_mlp(layers_dims, activation, output_activation):\n",
                "    \"\"\"Create a multi-layer perceptron with specified architecture.\"\"\"\n",
                "    layers = []\n",
                "    for i in range(len(layers_dims) - 1):\n",
                "        layers.append(nn.Linear(layers_dims[i], layers_dims[i + 1]))\n",
                "        if i < len(layers_dims) - 2:\n",
                "            layers.append(activation)\n",
                "    layers.append(output_activation)\n",
                "\n",
                "    net = nn.Sequential(*layers)\n",
                "\n",
                "    for layer in net:\n",
                "        if isinstance(layer, nn.Linear):\n",
                "            nn.init.xavier_normal_(layer.weight)\n",
                "            nn.init.zeros_(layer.bias)\n",
                "\n",
                "    return net\n",
                "\n",
                "\n",
                "activation_map = {\n",
                "    'tanh': nn.Tanh(),\n",
                "    'relu': nn.ReLU(),\n",
                "    'leaky_relu': nn.LeakyReLU(),\n",
                "    'sigmoid': nn.Sigmoid(),\n",
                "    'selu': nn.SELU(),\n",
                "    'square': Square(),\n",
                "    'softplus': nn.Softplus(),\n",
                "    'identity': nn.Identity()\n",
                "}"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2ffcfb17",
            "metadata": {},
            "source": [
                "## Module's configuration"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "id": "33bd675d",
            "metadata": {},
            "outputs": [],
            "source": [
                "@dataclass\n",
                "class SIRConfig:\n",
                "    \"\"\"Configuration for SIR PINN model and training.\"\"\"\n",
                "    # Model parameters\n",
                "    N: float = 56e6\n",
                "    delta: float = 1 / 5\n",
                "    r0: float = 3.0\n",
                "    beta_true: float = delta * r0\n",
                "    initial_beta: float = 0.5\n",
                "    \n",
                "    # Neural network architecture\n",
                "    hidden_layers: List[int] = field(default_factory=lambda: 4 * [50])\n",
                "    activation: str = 'tanh'\n",
                "    output_activation: str = 'square'\n",
                "    \n",
                "    # Initial conditions (I0, R0)\n",
                "    initial_conditions: List[float] = field(default_factory=lambda: [1., 0.])\n",
                "    \n",
                "    # Training parameters\n",
                "    learning_rate: float = 1e-3\n",
                "    batch_size: int = 100\n",
                "    max_epochs: int = 500\n",
                "    \n",
                "    # Scheduler parameters\n",
                "    scheduler_factor: float = 0.5\n",
                "    scheduler_patience: int = 100\n",
                "    scheduler_threshold: float = 0.01\n",
                "    scheduler_min_lr: float = 1e-6\n",
                "    \n",
                "    # Early stopping\n",
                "    early_stopping_patience: int = 200\n",
                "    \n",
                "    # Loss weights\n",
                "    pde_weight: float = 1.\n",
                "    ic_weight: float = 1.\n",
                "    data_weight: float = 1.\n",
                "    \n",
                "    # Dataset parameters\n",
                "    time_domain: Tuple[int, int] = (0, 90)\n",
                "    collocation_points: int = 6000\n",
                "    \n",
                "    # Logging\n",
                "    log_every_n_steps: int = 100"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "7120ac1ce626e51c",
            "metadata": {},
            "source": [
                "## Dataset creation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 31,
            "id": "7602c2b769e44162",
            "metadata": {},
            "outputs": [],
            "source": [
                "class SIRDataset(Dataset):\n",
                "    \"\"\"Dataset for SIR PINN training.\"\"\"\n",
                "    def __init__(\n",
                "        self, \n",
                "        t_obs: np.ndarray, \n",
                "        i_obs: np.ndarray, \n",
                "        time_domain: Tuple[float, float] = (0.0, 90.0), \n",
                "        n_collocation: int = 6000\n",
                "    ):\n",
                "        \"\"\"\n",
                "        Initialize dataset with observation points and random collocation points.\n",
                "        \n",
                "        Args:\n",
                "            t_obs: Observation time points\n",
                "            i_obs: Observed infected population at each time point\n",
                "            time_domain: (t_min, t_max) time range\n",
                "            n_collocation: Number of random collocation points to generate\n",
                "        \"\"\"\n",
                "        self.t_obs = torch.tensor(t_obs, dtype=torch.float32).reshape(-1, 1)\n",
                "        self.i_obs = torch.tensor(i_obs, dtype=torch.float32).reshape(-1, 1)\n",
                "        \n",
                "        t_min, t_max = time_domain\n",
                "        rand_t = np.expm1(np.random.uniform(np.log1p(t_min), np.log1p(t_max), n_collocation))\n",
                "        self.t_collocation = torch.tensor(rand_t, dtype=torch.float32).reshape(-1, 1)\n",
                "        \n",
                "        self.t_combined = torch.cat([self.t_obs, self.t_collocation], dim=0)\n",
                "        \n",
                "        self.is_obs = torch.zeros(len(self.t_combined), dtype=torch.bool)\n",
                "        self.is_obs[:len(self.t_obs)] = True\n",
                "        \n",
                "        self.i_targets = torch.zeros(len(self.t_combined), 1, dtype=torch.float32)\n",
                "        self.i_targets[:len(self.t_obs)] = self.i_obs\n",
                "        \n",
                "    def __len__(self):\n",
                "        return len(self.t_combined)\n",
                "    \n",
                "    def __getitem__(self, idx):\n",
                "        return {\n",
                "            't': self.t_combined[idx],\n",
                "            'is_obs': self.is_obs[idx],\n",
                "            'i_target': self.i_targets[idx]\n",
                "        }"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cb36a9738f8dd15c",
            "metadata": {},
            "source": [
                "## Module definition"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "id": "998d6e196fb0334a",
            "metadata": {},
            "outputs": [],
            "source": [
                "class SIRPINN(LightningModule):\n",
                "    \"\"\"Physics-Informed Neural Network for SIR model parameter identification.\"\"\"\n",
                "    \n",
                "    def __init__(self, config: SIRConfig):\n",
                "        super().__init__()\n",
                "        self.save_hyperparameters()\n",
                "        self.config = config\n",
                "        \n",
                "        layers_dims = [1] + config.hidden_layers + [1]\n",
                "        activation = activation_map.get(config.activation)\n",
                "        output_activation = activation_map.get(config.output_activation)\n",
                "        \n",
                "        self.net_S = create_mlp(layers_dims, activation, output_activation)\n",
                "        self.net_I = create_mlp(layers_dims, activation, output_activation)\n",
                "        \n",
                "        self.beta = nn.Parameter(torch.tensor(config.initial_beta, dtype=torch.float32))\n",
                "        \n",
                "        self.N = config.N\n",
                "        self.delta = config.delta\n",
                "        \n",
                "        self.loss_fn = nn.MSELoss()\n",
                "        \n",
                "        self.beta_history = []\n",
                "        \n",
                "    def forward(self, t: torch.Tensor) -> torch.Tensor:\n",
                "        \"\"\"\n",
                "        Forward pass to compute S, I, R values at time t.\n",
                "        \n",
                "        Args:\n",
                "            t: Time points tensor of shape [batch_size, 1]\n",
                "            \n",
                "        Returns:\n",
                "            Tensor of shape [batch_size, 3] with [S, I, R] values\n",
                "        \"\"\"\n",
                "        S = self.net_S(t)\n",
                "        I = self.net_I(t)\n",
                "        R = self.N - S - I\n",
                "        \n",
                "        return torch.cat([S, I, R], dim=1)\n",
                "        \n",
                "    @torch.inference_mode(False)\n",
                "    def compute_ode_residuals(self, t: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:\n",
                "        \"\"\"\n",
                "        Compute residuals of the SIR ODEs using automatic differentiation.\n",
                "        \n",
                "        Args:\n",
                "            t: Time points tensor of shape [batch_size, 1]\n",
                "            \n",
                "        Returns:\n",
                "            Tuple of residual tensors (res_S, res_I)\n",
                "        \"\"\"\n",
                "        t_tensor = t.clone().detach().requires_grad_(True)\n",
                "    \n",
                "        S = self.net_S(t_tensor)\n",
                "        I = self.net_I(t_tensor)\n",
                "        \n",
                "        dS_dt = torch.autograd.grad(\n",
                "            S, t_tensor, grad_outputs=torch.ones_like(S), create_graph=True\n",
                "        )[0]        \n",
                "        dI_dt = torch.autograd.grad(\n",
                "            I, t_tensor, grad_outputs=torch.ones_like(I), create_graph=True\n",
                "        )[0]\n",
                "\n",
                "        res_S = dS_dt + self.beta * S * I\n",
                "        res_I = dI_dt - self.beta * S * I + self.delta * I\n",
                "        \n",
                "        return res_S, res_I\n",
                "    \n",
                "    def pde_loss(self, t: torch.Tensor) -> torch.Tensor:\n",
                "        \"\"\"Compute PDE residual loss.\"\"\"\n",
                "        res_S, res_I = self.compute_ode_residuals(t)\n",
                "        loss_S = self.loss_fn(res_S, torch.zeros_like(res_S))\n",
                "        loss_I = self.loss_fn(res_I, torch.zeros_like(res_I))\n",
                "\n",
                "        return loss_S + loss_I\n",
                "    \n",
                "    def ic_loss(self) -> torch.Tensor:\n",
                "        \"\"\"Compute initial condition loss.\"\"\"\n",
                "        t0 = torch.zeros(1, 1, device=self.device, dtype=torch.float32)\n",
                "        \n",
                "        i0, r0 = self.config.initial_conditions\n",
                "        ic_true = torch.tensor(\n",
                "            [self.N - i0 - r0, i0, r0],\n",
                "            device=self.device,\n",
                "            dtype=torch.float32\n",
                "        ).reshape(1, 3)\n",
                "        \n",
                "        ic_pred = self(t0)\n",
                "        return self.loss_fn(ic_pred, ic_true)\n",
                "    \n",
                "    def data_loss(self, t_obs: torch.Tensor, i_obs: torch.Tensor) -> torch.Tensor:\n",
                "        \"\"\"Compute data fitting loss.\"\"\"\n",
                "        if t_obs.shape[0] == 0:  # No observations in batch\n",
                "            return torch.tensor(0.0, device=self.device)\n",
                "        \n",
                "        i_pred = self(t_obs)[:, 1:2]\n",
                "        return self.loss_fn(i_pred, i_obs)\n",
                "    \n",
                "    def training_step(self, batch):\n",
                "        t = batch['t']\n",
                "        is_obs = batch['is_obs']\n",
                "        i_target = batch['i_target']\n",
                "        \n",
                "        t_obs = t[is_obs] if is_obs.any() else torch.zeros((0, 1), device=self.device)\n",
                "        i_obs = i_target[is_obs] if is_obs.any() else torch.zeros((0, 1), device=self.device)\n",
                "        \n",
                "        pde_loss_val = self.pde_loss(t)\n",
                "        ic_loss_val = self.ic_loss()\n",
                "        data_loss_val = self.data_loss(t_obs, i_obs)\n",
                "        \n",
                "        total_loss = (\n",
                "            self.config.pde_weight * pde_loss_val +\n",
                "            self.config.ic_weight * ic_loss_val +\n",
                "            self.config.data_weight * data_loss_val\n",
                "        )\n",
                "        \n",
                "        self.log('train/pde_loss', pde_loss_val )\n",
                "        self.log('train/ic_loss', ic_loss_val)\n",
                "        self.log('train/data_loss', data_loss_val)\n",
                "        self.log('train/total_loss', total_loss, prog_bar=True)\n",
                "        self.log('train/beta', self.beta.item(), prog_bar=True)\n",
                "        \n",
                "        self.beta_history.append(self.beta.item())\n",
                "        \n",
                "        return total_loss\n",
                "    \n",
                "    def validation_step(self, batch):\n",
                "        t = batch['t']\n",
                "        is_obs = batch['is_obs']\n",
                "        i_target = batch['i_target']\n",
                "        \n",
                "        t_obs = t[is_obs] if is_obs.any() else torch.zeros((0, 1), device=self.device)\n",
                "        i_obs = i_target[is_obs] if is_obs.any() else torch.zeros((0, 1), device=self.device)\n",
                "        \n",
                "        pde_loss_val = self.pde_loss(t)\n",
                "        ic_loss_val = self.ic_loss()\n",
                "        data_loss_val = self.data_loss(t_obs, i_obs)\n",
                "        \n",
                "        total_loss = (\n",
                "            self.config.pde_weight * pde_loss_val +\n",
                "            self.config.ic_weight * ic_loss_val +\n",
                "            self.config.data_weight * data_loss_val\n",
                "        )\n",
                "        \n",
                "        self.log('val/pde_loss', pde_loss_val)\n",
                "        self.log('val/ic_loss', ic_loss_val)\n",
                "        self.log('val/data_loss', data_loss_val)\n",
                "        self.log('val/total_loss', total_loss)\n",
                "        \n",
                "        return total_loss\n",
                "    \n",
                "    @torch.no_grad()\n",
                "    def predict_sir(self, t):\n",
                "        \"\"\"Predict SIR values at specified time points.\"\"\"\n",
                "        t_tensor = torch.tensor(t, dtype=torch.float32).reshape(-1, 1).to(self.device)\n",
                "        return self(t_tensor).cpu().numpy()\n",
                "    \n",
                "    def configure_optimizers(self):\n",
                "        optimizer = torch.optim.Adam(\n",
                "            self.parameters(), \n",
                "            lr=self.config.learning_rate\n",
                "        )\n",
                "        \n",
                "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
                "            optimizer,\n",
                "            mode='min',\n",
                "            factor=self.config.scheduler_factor,\n",
                "            patience=self.config.scheduler_patience,\n",
                "            threshold=self.config.scheduler_threshold,\n",
                "            min_lr=self.config.scheduler_min_lr\n",
                "        )\n",
                "        \n",
                "        return {\n",
                "            'optimizer': optimizer,\n",
                "            'lr_scheduler': {\n",
                "                'scheduler': scheduler,\n",
                "                'monitor': 'val/total_loss',\n",
                "                'interval': 'epoch',\n",
                "                'frequency': 1\n",
                "            }\n",
                "        }"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "1e0b9eaa",
            "metadata": {},
            "source": [
                "## Training definition"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 33,
            "id": "45bc6a5a",
            "metadata": {},
            "outputs": [],
            "source": [
                "from lightning import Callback\n",
                "\n",
                "\n",
                "def train_sir_pinn(t_obs, i_obs, override_config=None):\n",
                "    \"\"\"\n",
                "    Train a SIR PINN model using the provided observations.\n",
                "    \n",
                "    Args:\n",
                "        t_obs: Observation time points\n",
                "        i_obs: Observed infected proportions\n",
                "        override_config: Configuration object (optional)\n",
                "        \n",
                "    Returns:\n",
                "        Trained PINN model\n",
                "    \"\"\"\n",
                "    if override_config is None:\n",
                "        config = SIRConfig()\n",
                "    else:\n",
                "        config = override_config\n",
                "    \n",
                "    # Create dataset and dataloaders\n",
                "    dataset = SIRDataset(\n",
                "        t_obs=t_obs,\n",
                "        i_obs=i_obs,\n",
                "        time_domain=config.time_domain,\n",
                "        n_collocation=config.collocation_points\n",
                "    )\n",
                "    \n",
                "    train_dataset, val_dataset = torch.utils.data.random_split(dataset, [0.8, 0.2])\n",
                "    \n",
                "    train_loader = DataLoader(\n",
                "        train_dataset,\n",
                "        batch_size=config.batch_size,\n",
                "        shuffle=True,\n",
                "        num_workers=0\n",
                "    )\n",
                "    \n",
                "    val_loader = DataLoader(\n",
                "        val_dataset,\n",
                "        batch_size=config.batch_size,\n",
                "        shuffle=False,\n",
                "        num_workers=0\n",
                "    )\n",
                "    \n",
                "    # Create model\n",
                "    model = SIRPINN(config)\n",
                "\n",
                "    # Setup callbacks\n",
                "    callbacks: list[Callback] = [\n",
                "        # EarlyStopping(\n",
                "        #     monitor='val/total_loss',\n",
                "        #     patience=config.early_stopping_patience,\n",
                "        #     mode='min'\n",
                "        # ),\n",
                "        # ModelCheckpoint(\n",
                "        #     monitor='val/total_loss',\n",
                "        #     filename='sir-pinn-{epoch:02d}-{val/total_loss:.4e}',\n",
                "        #     save_top_k=1,\n",
                "        #     mode='min'\n",
                "        # ),\n",
                "        LearningRateMonitor(logging_interval='epoch')\n",
                "    ]\n",
                "    \n",
                "    # Create trainer\n",
                "    trainer = Trainer(\n",
                "        max_epochs=config.max_epochs,\n",
                "        callbacks=callbacks,\n",
                "        log_every_n_steps=config.log_every_n_steps,\n",
                "        logger=TensorBoardLogger(save_dir='logs/', name='sir_pinn')\n",
                "    )\n",
                "    \n",
                "    # Train model\n",
                "    trainer.fit(model, train_loader, val_loader)\n",
                "    \n",
                "    # Load best model\n",
                "    # best_model_path = trainer.checkpoint_callback.best_model_path\n",
                "    # if best_model_path:\n",
                "    #     model = SIRPINN.load_from_checkpoint(best_model_path)\n",
                "    \n",
                "    return model"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "fe623e70",
            "metadata": {},
            "source": [
                "## Execution \n",
                "\n",
                "Generate syntethic data:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 34,
            "id": "58d0265a",
            "metadata": {},
            "outputs": [],
            "source": [
                "config = SIRConfig()\n",
                "\n",
                "def sir(x, _, d, b):\n",
                "  s, i, _ = x\n",
                "  l = b * i / config.N\n",
                "  ds_dt = -l * s\n",
                "  di_dt = l * s - d * i\n",
                "  dr_dt = d * i\n",
                "  return np.array([ds_dt, di_dt, dr_dt])\n",
                "\n",
                "i0, r0 = config.initial_conditions\n",
                "t_start, t_end = config.time_domain\n",
                "\n",
                "# Time domain for simulation\n",
                "t_obs = np.linspace(t_start, t_end, t_end - t_start + 1)\n",
                "\n",
                "solution = odeint(sir, [config.N - i0 - r0, i0, r0], t_obs, args=(config.delta, config.beta_true))\n",
                "s_true = solution[:, 0]\n",
                "i_true = solution[:, 1]\n",
                "r_true = solution[:, 2]\n",
                "\n",
                "i_obs = np.random.poisson(i_true)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "abf06f82",
            "metadata": {},
            "source": [
                "Execute the training with the generated data:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 35,
            "id": "7a5009cc",
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "You are using the plain ModelCheckpoint callback. Consider using LitModelCheckpoint which with seamless uploading to Model registry.\n",
                        "GPU available: True (mps), used: True\n",
                        "TPU available: False, using: 0 TPU cores\n",
                        "HPU available: False, using: 0 HPUs\n",
                        "\n",
                        "  | Name         | Type       | Params | Mode \n",
                        "----------------------------------------------------\n",
                        "0 | net_S        | Sequential | 7.8 K  | train\n",
                        "1 | net_I        | Sequential | 7.8 K  | train\n",
                        "2 | loss_fn      | MSELoss    | 0      | train\n",
                        "  | other params | n/a        | 1      | n/a  \n",
                        "----------------------------------------------------\n",
                        "15.6 K    Trainable params\n",
                        "0         Non-trainable params\n",
                        "15.6 K    Total params\n",
                        "0.062     Total estimated model params size (MB)\n",
                        "15        Modules in train mode\n",
                        "0         Modules in eval mode\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "781c74130b0547d8942b78a7ab1f023a",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "/Users/giacomo/.conda/envs/pinn/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py:310: The number of training batches (49) is smaller than the logging interval Trainer(log_every_n_steps=100). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "254fe5628b224441ab2d03043f18f9d7",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Training: |          | 0/? [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "be87086f5fc34f178e5c96e357c7b101",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Validation: |          | 0/? [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "4ded9aa5b48344f58193c4ad4c4f0f32",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Validation: |          | 0/? [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "ebef3d40bd46440cba3fc9d08cba2924",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Validation: |          | 0/? [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "4b41874966684c01bc0f3661fdd802fe",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Validation: |          | 0/? [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "58ee02d1c26249aea1dee4ca218d0197",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Validation: |          | 0/? [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "ce5122fc4b494652b13ba659fe0b824d",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Validation: |          | 0/? [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "0635ab5fb4144630abce33b9cb7f1322",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Validation: |          | 0/? [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "74bf83ef437e4469bc5dffa6d12579d5",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Validation: |          | 0/? [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "d955aceb1f3f4edf8d78a1201cfff769",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Validation: |          | 0/? [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "39d882c89eb64bb7bd461c1459dc93c7",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Validation: |          | 0/? [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "62805d1c7091415b82d5d2a22803188c",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Validation: |          | 0/? [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "f962050f8c9c4a03a4c7385f5b29faf4",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Validation: |          | 0/? [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "b8ecc7e2fdb048c08ab12b1301f28ffb",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Validation: |          | 0/? [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "6a0f1845cce84f81a7c82e058b31fa12",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Validation: |          | 0/? [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "10325996204f466bb024d4ec8c047f1c",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Validation: |          | 0/? [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "90b633d4f07448deb042336fa1fd4be7",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Validation: |          | 0/? [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "96fa61d7119d4e4083952d201ab4231f",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Validation: |          | 0/? [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "b52d74d03cee4f5a800fe88d8d0b1425",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Validation: |          | 0/? [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "c7b3552297b242a0a799df530b4930c1",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Validation: |          | 0/? [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "e87aa58882c64e35b687c7c50adcf521",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Validation: |          | 0/? [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "ec6ed96cdb424183849ae14ca4fcc07c",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Validation: |          | 0/? [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "1288fe4124af4500ab1462a735c1acea",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Validation: |          | 0/? [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "a54251e3a9e341d7aea6dc93effde241",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Validation: |          | 0/? [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "d5a8ecbfb4df446593165b3abbbbb9a9",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Validation: |          | 0/? [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "2de66e09d5574e5ba787f14d8b0c1a79",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Validation: |          | 0/? [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "0d01366250444f9589b7b7adaf6e7fc5",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Validation: |          | 0/? [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "b93b11c76d8c4f369e1f7e143b03e97e",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "Validation: |          | 0/? [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
                    ]
                },
                {
                    "ename": "NameError",
                    "evalue": "name 'exit' is not defined",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
                        "File \u001b[0;32m~/.conda/envs/pinn/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py:48\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
                        "File \u001b[0;32m~/.conda/envs/pinn/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py:599\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    593\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    594\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    595\u001b[0m     ckpt_path,\n\u001b[1;32m    596\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    597\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    598\u001b[0m )\n\u001b[0;32m--> 599\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n",
                        "File \u001b[0;32m~/.conda/envs/pinn/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py:1012\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m-> 1012\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n",
                        "File \u001b[0;32m~/.conda/envs/pinn/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py:1056\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[0;32m-> 1056\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
                        "File \u001b[0;32m~/.conda/envs/pinn/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py:216\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start()\n\u001b[0;32m--> 216\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n",
                        "File \u001b[0;32m~/.conda/envs/pinn/lib/python3.9/site-packages/lightning/pytorch/loops/fit_loop.py:455\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 455\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m~/.conda/envs/pinn/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py:150\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end(data_fetcher)\n",
                        "File \u001b[0;32m~/.conda/envs/pinn/lib/python3.9/site-packages/lightning/pytorch/loops/training_epoch_loop.py:320\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.advance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mlightning_module\u001b[38;5;241m.\u001b[39mautomatic_optimization:\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;66;03m# in automatic optimization, there can only be one optimizer\u001b[39;00m\n\u001b[0;32m--> 320\u001b[0m     batch_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautomatic_optimization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
                        "File \u001b[0;32m~/.conda/envs/pinn/lib/python3.9/site-packages/lightning/pytorch/loops/optimization/automatic.py:192\u001b[0m, in \u001b[0;36m_AutomaticOptimization.run\u001b[0;34m(self, optimizer, batch_idx, kwargs)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;66;03m# BACKWARD PASS\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;66;03m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 192\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m result \u001b[38;5;241m=\u001b[39m closure\u001b[38;5;241m.\u001b[39mconsume_result()\n",
                        "File \u001b[0;32m~/.conda/envs/pinn/lib/python3.9/site-packages/lightning/pytorch/loops/optimization/automatic.py:270\u001b[0m, in \u001b[0;36m_AutomaticOptimization._optimizer_step\u001b[0;34m(self, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[38;5;66;03m# model hook\u001b[39;00m\n\u001b[0;32m--> 270\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_lightning_module_hook\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moptimizer_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_step_and_backward_closure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_accumulate:\n",
                        "File \u001b[0;32m~/.conda/envs/pinn/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py:176\u001b[0m, in \u001b[0;36m_call_lightning_module_hook\u001b[0;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 176\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
                        "File \u001b[0;32m~/.conda/envs/pinn/lib/python3.9/site-packages/lightning/pytorch/core/module.py:1302\u001b[0m, in \u001b[0;36mLightningModule.optimizer_step\u001b[0;34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001b[0m\n\u001b[1;32m   1278\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Override this method to adjust the default way the :class:`~lightning.pytorch.trainer.trainer.Trainer` calls\u001b[39;00m\n\u001b[1;32m   1279\u001b[0m \u001b[38;5;124;03mthe optimizer.\u001b[39;00m\n\u001b[1;32m   1280\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1300\u001b[0m \n\u001b[1;32m   1301\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1302\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer_closure\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m~/.conda/envs/pinn/lib/python3.9/site-packages/lightning/pytorch/core/optimizer.py:154\u001b[0m, in \u001b[0;36mLightningOptimizer.step\u001b[0;34m(self, closure, **kwargs)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strategy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 154\u001b[0m step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_on_after_step()\n",
                        "File \u001b[0;32m~/.conda/envs/pinn/lib/python3.9/site-packages/lightning/pytorch/strategies/strategy.py:239\u001b[0m, in \u001b[0;36mStrategy.optimizer_step\u001b[0;34m(self, optimizer, closure, model, **kwargs)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, pl\u001b[38;5;241m.\u001b[39mLightningModule)\n\u001b[0;32m--> 239\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecision_plugin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m~/.conda/envs/pinn/lib/python3.9/site-packages/lightning/pytorch/plugins/precision/precision.py:123\u001b[0m, in \u001b[0;36mPrecision.optimizer_step\u001b[0;34m(self, optimizer, model, closure, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m closure \u001b[38;5;241m=\u001b[39m partial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wrap_closure, model, optimizer, closure)\n\u001b[0;32m--> 123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m~/.conda/envs/pinn/lib/python3.9/site-packages/torch/optim/optimizer.py:487\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    483\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    484\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    485\u001b[0m             )\n\u001b[0;32m--> 487\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n",
                        "File \u001b[0;32m~/.conda/envs/pinn/lib/python3.9/site-packages/torch/optim/optimizer.py:91\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 91\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
                        "File \u001b[0;32m~/.conda/envs/pinn/lib/python3.9/site-packages/torch/optim/adam.py:202\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39menable_grad():\n\u001b[0;32m--> 202\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m group \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_groups:\n",
                        "File \u001b[0;32m~/.conda/envs/pinn/lib/python3.9/site-packages/lightning/pytorch/plugins/precision/precision.py:109\u001b[0m, in \u001b[0;36mPrecision._wrap_closure\u001b[0;34m(self, model, optimizer, closure)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"This double-closure allows makes sure the ``closure`` is executed before the ``on_before_optimizer_step``\u001b[39;00m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;124;03mhook is called.\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    107\u001b[0m \n\u001b[1;32m    108\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 109\u001b[0m closure_result \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_after_closure(model, optimizer)\n",
                        "File \u001b[0;32m~/.conda/envs/pinn/lib/python3.9/site-packages/lightning/pytorch/loops/optimization/automatic.py:146\u001b[0m, in \u001b[0;36mClosure.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Tensor]:\n\u001b[0;32m--> 146\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\u001b[38;5;241m.\u001b[39mloss\n",
                        "File \u001b[0;32m~/.conda/envs/pinn/lib/python3.9/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m~/.conda/envs/pinn/lib/python3.9/site-packages/lightning/pytorch/loops/optimization/automatic.py:131\u001b[0m, in \u001b[0;36mClosure.closure\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39menable_grad()\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mclosure\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ClosureResult:\n\u001b[0;32m--> 131\u001b[0m     step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m step_output\u001b[38;5;241m.\u001b[39mclosure_loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
                        "File \u001b[0;32m~/.conda/envs/pinn/lib/python3.9/site-packages/lightning/pytorch/loops/optimization/automatic.py:319\u001b[0m, in \u001b[0;36m_AutomaticOptimization._training_step\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\n\u001b[0;32m--> 319\u001b[0m training_step_output \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtraining_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mpost_training_step()  \u001b[38;5;66;03m# unused hook - call anyway for backward compatibility\u001b[39;00m\n",
                        "File \u001b[0;32m~/.conda/envs/pinn/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py:328\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 328\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    330\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
                        "File \u001b[0;32m~/.conda/envs/pinn/lib/python3.9/site-packages/lightning/pytorch/strategies/strategy.py:391\u001b[0m, in \u001b[0;36mStrategy.training_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_redirection(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_step\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 391\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
                        "Cell \u001b[0;32mIn[32], line 105\u001b[0m, in \u001b[0;36mSIRPINN.training_step\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    103\u001b[0m i_target \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mi_target\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m--> 105\u001b[0m t_obs \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m[\u001b[49m\u001b[43mis_obs\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m is_obs\u001b[38;5;241m.\u001b[39many() \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m), device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    106\u001b[0m i_obs \u001b[38;5;241m=\u001b[39m i_target[is_obs] \u001b[38;5;28;01mif\u001b[39;00m is_obs\u001b[38;5;241m.\u001b[39many() \u001b[38;5;28;01melse\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m), device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n",
                        "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
                        "\nDuring handling of the above exception, another exception occurred:\n",
                        "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
                        "Cell \u001b[0;32mIn[35], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_sir_pinn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt_obs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi_obs\u001b[49m\u001b[43m)\u001b[49m\n",
                        "Cell \u001b[0;32mIn[33], line 73\u001b[0m, in \u001b[0;36mtrain_sir_pinn\u001b[0;34m(t_obs, i_obs, override_config)\u001b[0m\n\u001b[1;32m     65\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     66\u001b[0m     max_epochs\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmax_epochs,\n\u001b[1;32m     67\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[1;32m     68\u001b[0m     log_every_n_steps\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mlog_every_n_steps,\n\u001b[1;32m     69\u001b[0m     logger\u001b[38;5;241m=\u001b[39mTensorBoardLogger(save_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogs/\u001b[39m\u001b[38;5;124m'\u001b[39m, name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msir_pinn\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     70\u001b[0m )\n\u001b[1;32m     72\u001b[0m \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;66;03m# Load best model\u001b[39;00m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;66;03m# best_model_path = trainer.checkpoint_callback.best_model_path\u001b[39;00m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;66;03m# if best_model_path:\u001b[39;00m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m#     model = SIRPINN.load_from_checkpoint(best_model_path)\u001b[39;00m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
                        "File \u001b[0;32m~/.conda/envs/pinn/lib/python3.9/site-packages/lightning/pytorch/trainer/trainer.py:561\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshould_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 561\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
                        "File \u001b[0;32m~/.conda/envs/pinn/lib/python3.9/site-packages/lightning/pytorch/trainer/call.py:65\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(launcher, _SubprocessScriptLauncher):\n\u001b[1;32m     64\u001b[0m         launcher\u001b[38;5;241m.\u001b[39mkill(_get_sigkill_signal())\n\u001b[0;32m---> 65\u001b[0m     \u001b[43mexit\u001b[49m(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[1;32m     68\u001b[0m     _interrupt(trainer, exception)\n",
                        "\u001b[0;31mNameError\u001b[0m: name 'exit' is not defined"
                    ]
                }
            ],
            "source": [
                "model = train_sir_pinn(t_obs, i_obs)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "f2d0a782",
            "metadata": {},
            "source": [
                "## Evaluation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e1af5d8b",
            "metadata": {},
            "outputs": [],
            "source": [
                "t_pred = np.linspace(t_start, t_end, 1000)\n",
                "pred_sir = model.predict_sir(t_pred)\n",
                "s_pred, i_pred, r_pred = pred_sir.T\n",
                "pred_beta = model.beta.item()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d5fde243",
            "metadata": {},
            "source": [
                "Model predition"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a2e75ea2",
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(12, 6))\n",
                "\n",
                "sns.lineplot(x=t_pred, y=s_true, label=\"$S_{\\\\mathrm{true}}$\")\n",
                "sns.lineplot(x=t_pred, y=s_pred, label=\"$S_{\\\\mathrm{pred}}$\", linestyle=\"--\")\n",
                "sns.lineplot(x=t_pred, y=i_true, label=\"$I_{\\\\mathrm{true}}$\")\n",
                "sns.lineplot(x=t_pred, y=i_pred, label=\"$I_{\\\\mathrm{pred}}$\", linestyle=\"--\")\n",
                "sns.lineplot(x=t_pred, y=r_true, label=\"$R_{\\\\mathrm{true}}$\")\n",
                "sns.lineplot(x=t_pred, y=r_pred, label=\"$R_{\\\\mathrm{pred}}$\", linestyle=\"--\")\n",
                "\n",
                "plt.title('True vs Predicted SIR Dynamics (predicted $\\\\beta$ = {pred_beta:.4f})', fontsize=14)\n",
                "plt.xlabel('Time (days)', fontsize=12)\n",
                "plt.ylabel('Fraction of Population', fontsize=12)\n",
                "plt.legend()\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5f4ea337",
            "metadata": {},
            "source": [
                "Beta evolution"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d0af0c9e",
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(12, 6))\n",
                "\n",
                "sns.lineplot(data=model.beta_history, label='$\\\\beta$')\n",
                "\n",
                "plt.title(f'$\\\\beta$ Evolution', fontsize=14)\n",
                "plt.xlabel('Iteration', fontsize=12)\n",
                "plt.ylabel('$\\\\beta$ value', fontsize=12)\n",
                "plt.legend()\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "pinn",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.9.21"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
